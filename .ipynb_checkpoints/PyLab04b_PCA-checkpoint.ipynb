{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "innocent-expression",
   "metadata": {},
   "source": [
    "# Python Lab 04b: PCA and k-Means (Toy Examples)\n",
    "\n",
    "## Francesco Della Santa, Computational Linear Algebra for Large Scale Problems, Politecnico di Torino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** ATTENTION! *****\n",
    "# If you want that the \"%matplotlib widget\" works, you need the package ipympl (pip install ipympl)\n",
    "#\n",
    "#\n",
    "# MATPLOTLIB INTERACTIVE VISUALIZATION. REMOVE (OR COMMENT) IF YOU NEED TO PRINT THE NOTEBOOK AS A PDF, SOMETIMES IT DOES NOT WORK WELL...\n",
    "%matplotlib widget\n",
    "#\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import display\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-conversion",
   "metadata": {},
   "source": [
    "# Loading Iris and Wine Datasets Available in Scikit-Learn\n",
    "\n",
    "Look at  https://scikit-learn.org/stable/modules/classes.html?highlight=datasets#module-sklearn.datasets for more information about toy-datasets available Scikit-Learn.\n",
    "\n",
    "We are going to work with the \"iris\" and the \"wine\" datasets.\n",
    "\n",
    "**Exercise:** read the documentation of *datasets.load_iris* and *datasets.load_wine* (link above) to understand the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = datasets.load_iris(as_frame=True)\n",
    "wine_dataset = datasets.load_wine(as_frame=True)\n",
    "\n",
    "iris = pd.concat([iris_dataset['data'], iris_dataset['target']], axis=1)\n",
    "wine = pd.concat([wine_dataset['data'], wine_dataset['target']], axis=1)\n",
    "\n",
    "display(iris)\n",
    "print(iris_dataset['DESCR'])\n",
    "print('')\n",
    "print('*************')\n",
    "print('')\n",
    "display(wine)\n",
    "print(wine_dataset['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-architecture",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "1. Iris dataset has all the features measured in centimeters and with value ranges of the same order of magnitude;\n",
    "1. Wine dataset has many different features, described by different unit measures and with value ranges chracterized by different oreders of magnitude\n",
    "\n",
    "**Consequences:** \n",
    "1. We can use PCA directly on the iris data without preprocessing;\n",
    "1. For the Wine dataset it is better to standardize the data before applying the PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-shell",
   "metadata": {},
   "source": [
    "**N.B.:** We show all the PCs, without dimensionality reduction, as a preliminary analysis of the datasets and the variance distribution among PCs. Moreover, we look also at the PCA applied to non-standardized wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris = iris.iloc[:, :-1]  # I do not consider the target column\n",
    "X_wine = wine.iloc[:, :-1]  # I do not consider the target column\n",
    "\n",
    "scaler_wine = StandardScaler()\n",
    "# Fit the scaler on the wine data... <---- TODO!\n",
    "\n",
    "X_wine_scaled = # standardize the wine data... <---- TODO!\n",
    "\n",
    "pca_iris = PCA()\n",
    "pca_wine = PCA()\n",
    "pca_wine_nostd = PCA()\n",
    "\n",
    "# Fit the pca objects on the iris data, the \"original\" wine data, and the standardized wine data.\n",
    "# ... <---- TODO!\n",
    "\n",
    "\n",
    "# HELP:\n",
    "# np.cumsum: numpy function that compute the cumulative sum of the input array\n",
    "# np.insert: numpy function that insert a value inside a vector in a specified position\n",
    "#\n",
    "# EXERCISE: read the documentation od the numpy functions above and of the following matplotlib functions\n",
    "# \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca_iris.explained_variance_ratio_))\n",
    "plt.title('IRIS')\n",
    "plt.ylim([0, 1.1])\n",
    "plt.xticks(ticks=np.arange(pca_iris.n_features_), \n",
    "           labels=[f'PC{i + 1}' for i in range(pca_iris.n_features_)])\n",
    "plt.xlabel('Principal components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca_wine_nostd.explained_variance_ratio_))\n",
    "plt.title('WINE (NO STANDARDIZATION)')\n",
    "plt.ylim([0, 1.1])\n",
    "plt.xticks(ticks=np.arange(pca_wine_nostd.n_features_), \n",
    "           labels=[f'PC{i + 1}' for i in range(pca_wine_nostd.n_features_)])\n",
    "plt.xlabel('Principal components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca_wine.explained_variance_ratio_))\n",
    "plt.title('WINE (WITH STANDARDIZATION)')\n",
    "plt.ylim([0, 1.1])\n",
    "plt.xticks(ticks=np.arange(pca_wine.n_features_), \n",
    "           labels=[f'PC{i + 1}' for i in range(pca_wine.n_features_)])\n",
    "plt.xlabel('Principal components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-parent",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "For this exercise, we arbitrarily select $m=2$ PCs for the iris dataset and $m=3$ PCs for the wine dataset. We oberve that the explained variance for the iris is almost $100\\%$ of the total variance while the explained variance for the wine is approximately $70\\%$ of the total variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize two new pca objects for the iris data and the standardized wine data.\n",
    "# Use m=2 PCs for the iris data and m=3 PCs for the wine data \n",
    "pca_iris_m = # ... <----------- TODO!\n",
    "pca_wine_m = # ... <----------- TODO!\n",
    "\n",
    "# Fit both the pca objects on the data\n",
    "# ... <---- TODO!\n",
    "\n",
    "\n",
    "# transform both the data using the pca objects\n",
    "Y_iris_m = # ... <---- TODO!\n",
    "Y_wine_m = # ... <---- TODO!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-wright",
   "metadata": {},
   "source": [
    "### Score Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(Y_iris_m[:, 0], Y_iris_m[:, 1], c=iris['target'].values)\n",
    "plt.title('IRIS - SCORE GRAPH')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# ATTENTION: for the 3D plots, always import Axes3D (from mpl_toolkits.mplot3d import Axes3D)\n",
    "\n",
    "fig_winescore = plt.figure()\n",
    "ax = fig_winescore.add_subplot(111, projection='3d')\n",
    "ax.scatter(Y_wine_m[:, 0], Y_wine_m[:, 1], Y_wine_m[:, 2], c=wine['target'].values)\n",
    "plt.title('WINE - SCORE GRAPH')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-helena",
   "metadata": {},
   "source": [
    "### Loading Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(pca_iris_m.n_features_):\n",
    "    plt.plot([0, pca_iris_m.components_[0, i]], [0, pca_iris_m.components_[1, i]], \n",
    "             label=X_iris.columns[i])\n",
    "plt.scatter(pca_iris_m.components_[0, :], pca_iris_m.components_[1, :], c='k')\n",
    "plt.legend()\n",
    "plt.title('IRIS - LOADING GRAPH')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# ATTENTION: for the 3D plots, always import Axes3D (from mpl_toolkits.mplot3d import Axes3D)\n",
    "\n",
    "tab20 = cm.tab20.colors\n",
    "\n",
    "fig_winescore = plt.figure()\n",
    "ax = fig_winescore.add_subplot(111, projection='3d')\n",
    "for i in range(pca_wine_m.n_features_):\n",
    "    ax.plot([0, pca_wine_m.components_[0, i]], [0, pca_wine_m.components_[1, i]], \n",
    "            [0, pca_wine_m.components_[2, i]],\n",
    "            label=X_wine.columns[i],\n",
    "            color=tab20[i]\n",
    "           )\n",
    "ax.scatter(pca_wine_m.components_[0, :], pca_wine_m.components_[1, :], pca_wine_m.components_[2, :], c='k')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), fontsize='xx-small')\n",
    "plt.title('WINE - LOADING GRAPH')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-costs",
   "metadata": {},
   "source": [
    "### Biplot\n",
    "\n",
    "**Exercise:** combine the previous codes to make a Biplot of both the iris data and the wine data in the reduce PCs' space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-championship",
   "metadata": {},
   "source": [
    "## PC Interpretation\n",
    "\n",
    "Let's have a look at the contribute of the original features to the PCs. We help the interpretation using the barplots to represent the PCs.\n",
    "\n",
    "Since for the iris dataset we are in $\\mathbb{R}^2$ and the number of features is relatively small, we can also look at the loading graph to help the interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5c4ba1-3c11-43f4-90af-199ee122bdb7",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(np.arange(pca_iris_m.n_features_), pca_iris_m.components_[0, :])\n",
    "plt.xticks(ticks=np.arange(pca_iris_m.n_features_), \n",
    "           labels=X_iris.columns.to_list(),\n",
    "           rotation=15)\n",
    "plt.title('IRIS - PC1')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(np.arange(pca_iris_m.n_features_), pca_iris_m.components_[1, :])\n",
    "plt.xticks(ticks=np.arange(pca_iris_m.n_features_), \n",
    "           labels=X_iris.columns.to_list(),\n",
    "           rotation=15)\n",
    "plt.title('IRIS - PC2')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tab10 = cm.tab10.colors\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i in range(pca_iris_m.n_features_):\n",
    "    ax[0].plot([0, pca_iris_m.components_[0, i]], [0, pca_iris_m.components_[1, i]], \n",
    "               label=X_iris.columns[i])\n",
    "ax[0].scatter(pca_iris_m.components_[0, :], pca_iris_m.components_[1, :], c='k')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('IRIS - LOADING GRAPH')\n",
    "ax[0].set_xlabel('PC1')\n",
    "ax[0].set_ylabel('PC2')\n",
    "ax[0].grid(visible=True, which='both')\n",
    "\n",
    "ax[1].bar(np.arange(pca_iris_m.n_features_), pca_iris_m.components_[0, :], color=tab10[:4])\n",
    "ax[1].set_xticks(ticks=np.arange(pca_iris_m.n_features_), \n",
    "           labels=X_iris.columns.to_list(),\n",
    "           rotation=15)\n",
    "ax[1].set_title('IRIS - PC1')\n",
    "ax[1].grid(visible=True, which='both')\n",
    "\n",
    "ax[2].bar(np.arange(pca_iris_m.n_features_), pca_iris_m.components_[1, :], color=tab10[:4])\n",
    "ax[2].set_xticks(ticks=np.arange(pca_iris_m.n_features_), \n",
    "           labels=X_iris.columns.to_list(),\n",
    "           rotation=15)\n",
    "ax[2].set_title('IRIS - PC2')\n",
    "ax[2].grid(visible=True, which='both')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-ordinary",
   "metadata": {},
   "source": [
    "#### Giving a Name to the Iris' PCs\n",
    "\n",
    "Looking at the barplots above, we can assign (**e.g.**) the following names to the PCs computed for the iris dataset:\n",
    "1. PC1: \"Petal Size & Sepal Length\";\n",
    "1. PC2: \"Sepal Size\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c3a3b-f1e4-40bc-9a1c-7e65b66eb356",
   "metadata": {},
   "source": [
    "### Wine Dataset\n",
    "\n",
    "Increasing the number $n$ of features, the barplot interpratation becomes more complicated. Then, *an heuristic idea*, can be the following.\n",
    "\n",
    "**IDEA (HEURISTIC):** for each PC, we consider only the the features with a contribute greater than an arbitrary threshold $\\epsilon$; i.e., only the features that have an absolute value greater than $\\epsilon$ for the PC. \n",
    "\n",
    "Since the PC are versors (i.e., they have norm equal to one), an *example* of possible threshold value is\n",
    "$$\\epsilon = \\sqrt{\\frac{1}{n}}\\,,$$\n",
    "since $||[\\epsilon, \\ldots ,\\epsilon]^\\top||=1$.\n",
    "\n",
    "**OTHER OPTIONS:** e.g., select the top $x\\%$ of original features with largest abosulte value, for each PC. In general, the importat thing is that any method is well-founded on right assumptions and/or hypotheses.\n",
    "\n",
    "Since we have a 3-dimensional PC-space, we can still use the loading graph to help the interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the threshold value\n",
    "eps = np.sqrt(1 / pca_wine_m.n_features_)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(np.arange(pca_wine_m.n_features_), pca_wine_m.components_[0, :])\n",
    "# --- RED LINE DENOTING THE THRESHOLD [-eps, +eps] -----------------\n",
    "plt.plot([-0.5, pca_wine_m.n_features_ - 0.5], [eps, eps], 'red')\n",
    "plt.plot([-0.5, pca_wine_m.n_features_ - 0.5], [-eps, -eps], 'red')\n",
    "# ------------------------------------------------------------------\n",
    "plt.xticks(ticks=np.arange(pca_wine_m.n_features_), \n",
    "           labels=X_wine.columns.to_list(),\n",
    "           rotation=80)\n",
    "plt.title('WINE - PC1')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(np.arange(pca_wine_m.n_features_), pca_wine_m.components_[1, :])\n",
    "# --- RED LINE DENOTING THE THRESHOLD [-eps, +eps] -----------------\n",
    "plt.plot([-0.5, pca_wine_m.n_features_ - 0.5], [eps, eps], 'red')\n",
    "plt.plot([-0.5, pca_wine_m.n_features_ - 0.5], [-eps, -eps], 'red')\n",
    "# ------------------------------------------------------------------\n",
    "plt.xticks(ticks=np.arange(pca_wine_m.n_features_), \n",
    "           labels=X_wine.columns.to_list(),\n",
    "           rotation=80)\n",
    "plt.title('WINE - PC2')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(np.arange(pca_wine_m.n_features_), pca_wine_m.components_[2, :])\n",
    "# --- RED LINE DENOTING THE THRESHOLD [-eps, +eps] -----------------\n",
    "plt.plot([-0.5, pca_wine_m.n_features_ - 0.5], [eps, eps], 'red')\n",
    "plt.plot([-0.5, pca_wine_m.n_features_ - 0.5], [-eps, -eps], 'red')\n",
    "# ------------------------------------------------------------------\n",
    "plt.xticks(ticks=np.arange(pca_wine_m.n_features_), \n",
    "           labels=X_wine.columns.to_list(),\n",
    "           rotation=80)\n",
    "plt.title('WINE - PC3')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig_winescore = plt.figure()\n",
    "ax = fig_winescore.add_subplot(111, projection='3d')\n",
    "for i in range(pca_wine_m.n_features_):\n",
    "    ax.plot([0, pca_wine_m.components_[0, i]], [0, pca_wine_m.components_[1, i]], \n",
    "            [0, pca_wine_m.components_[2, i]],\n",
    "            label=X_wine.columns[i],\n",
    "            color=tab20[i]\n",
    "           )\n",
    "ax.scatter(pca_wine_m.components_[0, :], pca_wine_m.components_[1, :], pca_wine_m.components_[2, :], c='k')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), fontsize='xx-small')\n",
    "plt.title('WINE - LOADING GRAPH')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].bar(np.arange(pca_wine_m.n_features_), pca_wine_m.components_[0, :], color=tab20[:pca_wine_m.n_features_])\n",
    "# --- RED LINE DENOTING THE THRESHOLD [-eps, +eps] -----------------\n",
    "ax[0].plot([-0.5, pca_wine_m.n_features_ - 0.5], [eps, eps], 'red')\n",
    "ax[0].plot([-0.5, pca_wine_m.n_features_ - 0.5], [-eps, -eps], 'red')\n",
    "# ------------------------------------------------------------------\n",
    "ax[0].set_xticks(ticks=np.arange(pca_wine_m.n_features_), \n",
    "           labels=X_wine.columns.to_list(),\n",
    "           rotation=80)\n",
    "ax[0].set_title('WINE - PC1')\n",
    "ax[0].grid(visible=True, which='both')\n",
    "ax[1].bar(np.arange(pca_wine_m.n_features_), pca_wine_m.components_[1, :], color=tab20[:pca_wine_m.n_features_])\n",
    "# --- RED LINE DENOTING THE THRESHOLD [-eps, +eps] -----------------\n",
    "ax[1].plot([-0.5, pca_wine_m.n_features_ - 0.5], [eps, eps], 'red')\n",
    "ax[1].plot([-0.5, pca_wine_m.n_features_ - 0.5], [-eps, -eps], 'red')\n",
    "# ------------------------------------------------------------------\n",
    "ax[1].set_xticks(ticks=np.arange(pca_wine_m.n_features_), \n",
    "           labels=X_wine.columns.to_list(),\n",
    "           rotation=80)\n",
    "ax[1].set_title('WINE - PC2')\n",
    "ax[1].grid(visible=True, which='both')\n",
    "ax[2].bar(np.arange(pca_wine_m.n_features_), pca_wine_m.components_[2, :], color=tab20[:pca_wine_m.n_features_])\n",
    "# --- RED LINE DENOTING THE THRESHOLD [-eps, +eps] -----------------\n",
    "ax[2].plot([-0.5, pca_wine_m.n_features_ - 0.5], [eps, eps], 'red')\n",
    "ax[2].plot([-0.5, pca_wine_m.n_features_ - 0.5], [-eps, -eps], 'red')\n",
    "# ------------------------------------------------------------------\n",
    "ax[2].set_xticks(ticks=np.arange(pca_wine_m.n_features_), \n",
    "           labels=X_wine.columns.to_list(),\n",
    "           rotation=80)\n",
    "ax[2].set_title('WINE - PC3')\n",
    "ax[2].grid(visible=True, which='both')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ii in range(3):\n",
    "    ind_great_pos_PCii = np.argwhere(pca_wine_m.components_[ii, :] >= eps).flatten()\n",
    "    ind_great_neg_PCii = np.argwhere(pca_wine_m.components_[ii, :] <= -eps).flatten()\n",
    "    \n",
    "    great_pos_PCii = [X_wine.columns[i] for i in ind_great_pos_PCii]\n",
    "    great_neg_PCii = [X_wine.columns[i] for i in ind_great_neg_PCii]\n",
    "    \n",
    "    print('')\n",
    "    print(f'****************** PC{ii+1} **********************')\n",
    "    print(f'HIGH-VALUED POSITIVE COMPONENTS: {great_pos_PCii}')\n",
    "    print('')\n",
    "    print(f'HIGH-VALUED NEGATIVE COMPONENTS: {great_neg_PCii}')\n",
    "    print('*********************************************')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdaade4-3566-4da8-acca-fe695c906668",
   "metadata": {},
   "source": [
    "#### Giving a Name to the Wine's PCs\n",
    "\n",
    "Looking at the barplots and the features printed above, we can assign names to the PCS. For this dataset, we need at least some knowledge about wines to be really able to give a good interpretation of the PCs. \n",
    "Then, the names given to the PCs can be something of this type:\n",
    "1. PC1: \"*Earthy Profile* (-) VS *Rich Blend* (+)\"; \n",
    "1. PC2: \"*Robust & Deep* (-) VS Hue (+)\";\n",
    "1. PC3: \"Ash & Alcalinity of Ash\".\n",
    "\n",
    "We higlighted in *italic* the PCs named useing knowledge about wines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fe90bb-00b8-40c9-b6f8-f9f0b899133c",
   "metadata": {},
   "source": [
    "# $k$-Means\n",
    "\n",
    "We now apply the $k$-Means algorithm w.r.t. the data reduced through the PCA. Then, we show the barplot of the centroids w.r.t. the PCs, trying to give an interpretation to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf5173-1e29-47c0-975b-d806cd5ad4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_iris = KMeans(n_clusters=3, random_state=random_state)\n",
    "km_wine = KMeans(n_clusters=3, random_state=random_state)\n",
    "\n",
    "km_iris.fit(Y_iris_m)\n",
    "km_wine.fit(Y_wine_m)\n",
    "\n",
    "maxs_iris_m = Y_iris_m.max(axis=0) \n",
    "mins_iris_m = Y_iris_m.min(axis=0) \n",
    "\n",
    "maxs_wine_m = Y_wine_m.max(axis=0) \n",
    "mins_wine_m = Y_wine_m.min(axis=0) \n",
    "\n",
    "irisPC1 = \"P.Sz_S.Len.\"\n",
    "irisPC2 = \"S.Sz\"\n",
    "\n",
    "winePC1 = \"EP_vs_RB\"\n",
    "winePC2 = \"RnD_vs_Hue\"\n",
    "winePC3 = \"Ash_AlcAsh\"\n",
    "\n",
    "fig_iris, ax_iris = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for ii in range(3):\n",
    "    ax_iris[ii].bar(np.arange(km_iris.cluster_centers_.shape[1]), maxs_iris_m, color='blue', alpha=0.15)\n",
    "    ax_iris[ii].bar(np.arange(km_iris.cluster_centers_.shape[1]), mins_iris_m, color='blue', alpha=0.15)\n",
    "    ax_iris[ii].bar(np.arange(km_iris.cluster_centers_.shape[1]), km_iris.cluster_centers_[ii, :])\n",
    "    ax_iris[ii].set_xticks(ticks=np.arange(km_iris.cluster_centers_.shape[1]))\n",
    "    ax_iris[ii].set_xticklabels(labels=[irisPC1, irisPC2], rotation=0)\n",
    "    ax_iris[ii].grid(visible=True, which='both')\n",
    "    ax_iris[ii].set_title(f'IRIS - CENTROID {ii+1}')\n",
    "\n",
    "\n",
    "fig_wine, ax_wine = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for ii in range(3):\n",
    "    ax_wine[ii].bar(np.arange(km_wine.cluster_centers_.shape[1]), maxs_wine_m, color='blue', alpha=0.15)\n",
    "    ax_wine[ii].bar(np.arange(km_wine.cluster_centers_.shape[1]), mins_wine_m, color='blue', alpha=0.15)\n",
    "    ax_wine[ii].bar(np.arange(km_wine.cluster_centers_.shape[1]), km_wine.cluster_centers_[ii, :])\n",
    "    ax_wine[ii].set_xticks(ticks=np.arange(km_wine.cluster_centers_.shape[1]))\n",
    "    ax_wine[ii].set_xticklabels(labels=[winePC1, winePC2, winePC3], rotation=0)\n",
    "    ax_wine[ii].grid(visible=True, which='both')\n",
    "    ax_wine[ii].set_title(f'WINE - CENTROID {ii+1}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91792957-b05c-41d1-9815-c521ec06155b",
   "metadata": {},
   "source": [
    "#### Giving a Name to the Centroids\n",
    "\n",
    "Looking at the barplots (the PC-coordinates of the centroids) printed above, we can assign names or brief descriptions to the clusters corresponding to the centroids.\n",
    "\n",
    "IRIS:\n",
    "1. Cluster 1: \"Irises with large petals and long sepals\"; \n",
    "1. Cluster 2: \"Irises with small petals and short sepals\";\n",
    "1. Cluster 3: \"Ireses in-the-average\";\n",
    "\n",
    "WINE:\n",
    "1. Cluster 1: \"Earthy, robust, and deep wines\";\n",
    "2. Cluster 2: \"Robust and deep wines with rich blend\";\n",
    "3. Cluster 3: \"Strongly-hued wines\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab0490a-5db8-4884-9c54-7f4b77ed97f5",
   "metadata": {},
   "source": [
    "## Score Graphs, Clusters, and Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2a007-2b70-433c-a0e1-74328b1ffbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_dict = {0: '*', 1: 'o', 2: 'd'}\n",
    "colors = cm.tab20.colors\n",
    "\n",
    "plt.figure()\n",
    "for ll in km_iris.labels_:\n",
    "    plt.scatter(Y_iris_m[km_iris.labels_ == ll, 0], Y_iris_m[km_iris.labels_ == ll, 1], c=[colors[ii] for ii in iris['target'].values[km_iris.labels_ == ll]], marker=markers_dict[ll])\n",
    "plt.scatter(km_iris.cluster_centers_[:, 0], km_iris.cluster_centers_[:, 1], c='black', marker='^')\n",
    "plt.title('IRIS - SCORE GRAPH (Symbol=Cluster, Color=Class)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig_winescore = plt.figure()\n",
    "ax = fig_winescore.add_subplot(111, projection='3d')\n",
    "for ll in km_iris.labels_:\n",
    "    ax.scatter(Y_wine_m[km_wine.labels_ == ll, 0], Y_wine_m[km_wine.labels_ == ll, 1], Y_wine_m[km_wine.labels_ == ll, 2], c=[colors[ii] for ii in wine['target'].values[km_wine.labels_ == ll]], marker=markers_dict[ll])\n",
    "ax.scatter(km_wine.cluster_centers_[:, 0], km_wine.cluster_centers_[:, 1], km_wine.cluster_centers_[:, 2], c='black', marker='^')\n",
    "plt.title('WINE - SCORE GRAPH  (Symbol=Cluster, Color=Class)')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f795934-8604-486b-b242-f6bff33bb620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
